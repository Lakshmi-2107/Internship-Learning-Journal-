# ðŸ“š Week 3 â€“ Session 1 Learnings
## Advanced LLM Systems & Intelligent Applications

This session expanded my understanding of how modern AI systems actually function beyond simple prompting.

---

#  Key Learnings

##  Understanding LLM Foundations

I learned that LLMs:

- Are prediction engines
- Use transformers
- Process tokens
- Have context limits

They do not "understand" like humans.

---

##  Importance of Token Efficiency

I now understand:

- Why shorter prompts save money
- How input + output tokens affect cost
- Why structured prompts are efficient

---

##  Embeddings & Similarity Search

This was a major concept.

I learned:

- Embeddings convert data into vectors
- Similar meaning â†’ closer vectors
- Enables semantic search
- Works beyond keywords

This is powerful for building smart search systems.

---

##  Retrieval Augmented Generation (RAG)

RAG solves hallucination issues.

Instead of trusting the model blindly:

- Retrieve documents
- Feed real data
- Generate grounded answers

This improves reliability.

---

##  Hybrid Search Systems

Combining:

- Keyword matching
- Vector similarity

gives both accuracy and contextual intelligence.

This is more powerful than either method alone.

---

##  Vision Models

I learned LLMs can:

- Analyze images
- Process videos
- Extract information from visuals

This expands AI beyond text-only tasks.

---

##  Structured Output & Schemas

Using schemas ensures:

- Consistent responses
- Clean JSON output
- Easier integration with apps

This is critical for production systems.

---

##  Function Calling & Agents

I understood how LLMs:

- Trigger functions
- Use tools
- Automate workflows

This moves from chatbots to intelligent systems.

---

##  Evaluation & Testing

AI systems must be tested.

Learned:

- Create prompt test cases
- Compare models
- Check cost and speed
- Use regression testing

Testing is essential for scalable AI applications.

---

#  Overall Growth

Before this session:

 I saw LLMs as simple chat tools  

After this session:

 I understand how to build structured, reliable AI systems  

Now I see how AI integrates into real-world applications.

---


# Session 2 Learnings  
## Practical Embeddings & RAG Systems

This session strengthened my understanding of how embeddings and retrieval systems power modern AI applications.

---

# What I Learned

##  Embeddings as Meaning Representation

I learned that embeddings:

- Convert text into vectors
- Capture semantic meaning
- Enable similarity comparison

They are foundational for AI search systems.

---

##  Cosine Similarity

I now understand:

- How similarity is calculated
- Why normalization matters
- How related concepts score higher

Mathematics supports semantic intelligence.

---

##  Multimodal Search

AI can compare:

- Text with images
- Image with image
- Text with text

This expands search capabilities beyond words.

---

##  Chunking Strategy

Large documents must be:

- Split into manageable parts
- Indexed separately
- Stored with unique IDs

Chunking makes RAG scalable.

---

##  RAG Workflow

Instead of asking GPT blindly:

- Retrieve relevant context
- Pass only useful data
- Generate grounded answers

This improves reliability and reduces cost.

---

##  Efficient API Usage

I learned:

- How to store embeddings once
- Avoid recomputing
- Reduce token usage
- Improve speed

Efficiency is key in real projects.

---

##  Deployment Awareness

Real-world systems require:

- Public repositories
- Correct URLs
- Valid tokens
- Environment configuration

Debugging skills are essential.

---

# ðŸ”¹ Growth Reflection

Before this session:

 I only knew basic embedding concepts.

After this session:

 I can implement a full RAG pipeline with chunking and retrieval.

This session connected theory with real implementation.

---


